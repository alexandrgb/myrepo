---
title: "Project 2"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
library(tidyverse)
```
## Alexandra Rivera (ar63757)

*Addressments:
Introduction- There are 132 observations.
Randomization Test- I didn't visualize the null distribution and didn't really interpret the results in context and I should not have used a t-test. Dose and weight were found to reject the null hypothesis and concluded that the means for each subject differed significantly.
Linear Regression- According to the interaction graph between concentration and time, there seems to be a slightly positive relationship between the two variables, the more time goes on the higher the concentration of theophylline in the subject. 





## Introduction
#### I selected the dataset "Theoph" which is a data frame based off of a study done in 1994 which observed the kinetics of the anti-asthmatic drug theophylline. There were twelve subjects who took doses of theophylline and serum concentrations were measured at 11 time points over the next 25 hours. It contains the variables subject, Wt (weight), Dose (dose of theophylline), Time (since drug administration), and conc (theophylline concentration in the sample). This dataset is interesting to me because I am interested in the analysis of healthcare data and hope to find a career in a biotech or pharmaceutical company interpreting medical data. I didn't have to tidy the data. I expect to find maybe that a couple of the subjects would have an outlying correlation for concentrations because the number of subjects is so small.
```{r}
head(Theoph)
```

## EDA
#### After observing the means for concentration and time, creating a multivariate plot for concentration and time, and a correlation matrix, it was visible that each subject had similar averages in time since drug administration for concentration measurements. There were some variations in the means of concentrations per subject, with subject 1 having the highest mean of concentrations and subject 6 having the lowest mean concentration.
```{r}
Theoph %>%
  group_by(Subject) %>%
  summarize(mean(conc), mean(Time)) %>%
  summarise(Theoph)

# Represent the means per subject
Theoph %>%
  select(Subject,Time,conc) %>%
  pivot_longer(-1,names_to='DV', values_to='measure') %>%
  ggplot(aes(Subject,measure,fill=Subject)) +
  geom_bar(stat="summary", fun = "mean") +
  geom_errorbar(stat="summary", fun.data = "mean_se", width=.5) +
  facet_wrap(~DV, nrow=2) +
  coord_flip() + 
  ylab("") + 
  theme(legend.position = "none")

# Inspect multivariate plots of response variable for each subject
ggplot(Theoph, aes(x = conc, y = Time)) +
  geom_point(alpha = .5) + 
  geom_density_2d(h=2) + 
  coord_fixed() + 
  facet_wrap(~Subject)

# correlation matrix
theoph_1 <- Theoph %>%
  select(-Subject)
cor(theoph_1) %>%
  as.data.frame %>%
  # convert row names to an explicit variable
  rownames_to_column %>%
  pivot_longer(-1, names_to = "other_var", values_to = "correlation") %>%
  ggplot(aes(rowname, ordered(other_var, levels = rev(sort(unique(other_var)))), fill=correlation)) +
  # Heatmap with geom_tile
  geom_tile() +
  # Change the scale to make the middle appear neutral
  scale_fill_gradient2(low="red",mid="white",high="blue") +
  # Overlay values
  geom_text(aes(label = round(correlation,2)), color = "black", size = 4) +
  # Give title and labels
  labs(title = "Correlation matrix for the dataset Theoph", x = "variable 1", y = "variable 2")

``` 

## MANOVA
#### After performing MANOVA tests, the effect of the subject on independent variables concentration, time, weight, and dose were shown. Significant differences were found among the 12 subjects for at least one of the dependent variables weight and dose (Pillai's trace = 2, pseudo F(11, 240) = 0.50886, p < 0.05). The null hypothesis is that for each response variable, weight and dose, the means for each group are equal. Univariate ANOVAs for each dependent variable were conducted as follow-up tests to the MANOVA, which were also significant for dose (F(11, 6.14) = 9.02e29, p < 0.001)  and weight (F(11,993.4) = 6.1e30, p < 0.001). Post hoc analysis was performed conducting pairwise comparisons to determine which subject differed in dose and weight. All Subjects were found to differ significantly from each other in terms of dose and weight after adjusting for multiple comparisons (Bonferroni ð›¼=.025). Assumptions did seem to have been met after visually checking for normality and equal variance.
```{r manova}
# assumptions 
ggplot(Theoph, aes(y = conc)) +
  geom_boxplot(aes(fill = as.factor(Subject)))

# Check for normality
Theoph %>%
  group_by(Subject) %>%
  summarize(p.value = shapiro.test(conc)$p.value)

# Check for equal variance
Theoph %>%
  group_by(Subject) %>%
  summarize(variance = var(conc))

manova_theoph <- manova(cbind(conc, Time) ~ Subject, data = Theoph)
manova_theoph1 <- manova(cbind(Wt, Dose) ~ Subject, data = Theoph)

# OUtput of MANOVA
summary(manova_theoph)
summary(manova_theoph1)

  # If MANOVA is significant then we can perform one-way ANOVA for each variable
  summary.aov(manova_theoph1)

    # If ANOVA is significant then we can perform post-hoc analysis
    # For weight
    pairwise.t.test(Theoph$Wt,Theoph$Subject, p.adj="none")
    # For dose
    pairwise.t.test(Theoph$Dose,Theoph$Subject, p.adj="none")


1-0.95^2
0.05/2
```


## Randomization test
#### The null hypothesis is that there is no significant mean difference across concentration and time, the alternative hypothesis is that there is a significant mean difference across concentration and time. After visualizing the result, it can be concluded that there are significant mean differences for reseampled randomizations.
```{r randomize}
# Keep the same condition, resample the time across conditions
perm1 <- data.frame(concentration = Theoph$conc, time = sample(Theoph$Time))
head(perm1) 

# Find the new mean difference
perm1 %>% 
  group_by(concentration) %>%
  summarize(means = mean(time)) %>%
  summarize(mean_diff = diff(means))

## Repeat randomization
# Keep the same condition, resample the time across conditions
perm2 <- data.frame(concentration = Theoph$conc, time = sample(Theoph$Time))
head(perm2)

# Find the new mean difference
perm2 %>% 
  group_by(concentration) %>%
  summarize(means = mean(time)) %>%
  summarize(mean_diff = diff(means))

``` 

## Linear Regression
#### The coefficient estimates for each subject as the dosage increases by 1 are provided. The proportions of variation in the response is explained by about 0.93. Assumptions for normality and homoscedasticity seem to pass, but linearity does not because of the QQ plot. Robust standard errors and bootstrapped standard errors both show no significant results based off of p-values, though standard errors overall increased as it went from original SEs to robust SEs to bootstrapped SEs.
``` {r}
# Fit a multiple linear regression model with both predictors
Theoph_c <- Theoph %>%
  mutate(conc_c = conc - mean(conc, na.rm=TRUE))
fit <- lm(Time ~ conc_c * Subject, data = Theoph_c)
summary(fit)

# mean of concentration
mean(Theoph$conc, na.rm=TRUE)

Theoph %>% 
  ggplot(aes(conc, Time)) +
  geom_smooth(aes(col=Subject),method="lm") +
  xlim(0,1.4) 

fit1 <- lm(Dose ~ Wt + Subject, data = Theoph)
summary(fit1)

fit2 <- lm(Dose ~ conc * Subject, data = Theoph)
summary(fit2)

# Residuals against fitted values plot to check for any problematic patterns (nonlinear, equal variance)
plot(fit, which = 1)

hist(fit$residuals)

# Q-Q plot to check for normality of the residuals
plot(fit, which = 2)


# Shapiro-Wilk test
# H0: normality
shapiro.test(fit$residuals)
# Kolmogorov-Smirnov test
# H0: normality
ks.test(fit$residuals, "pnorm", mean=0, sd(fit$residuals))
  # note: the error indicates that there are repeated values for the residuals
#install.packages("sandwich")
library(sandwich);
# Install a new package
 #install.packages("lmtest")
library(lmtest)

# Breusch-Pagan test
# H0: homoscedasticity
bptest(fit) 


# Robust Standard Errors
library(sandwich)
coeftest(fit, vcov = vcovHC(fit))
# When assumptions are violated (homoscedasticity, normality, small sample size)
# use bootstrap samples to estimate coefficients, SEs, fitted values, ...

# Example of estimating coefficients SEs
# Use the function replicate to repeat the process (similar to a for loop)
samp_SEs <- replicate(5, {
  # Bootstrap your data (resample observations)
  boot_data <- sample_frac(Theoph, replace = TRUE)
  # Fit regression model
  fitboot <- lm(Time ~ conc * Subject, data = boot_data)
  # Save the coefficients
  coef(fitboot)
})

# Estimated SEs
samp_SEs %>%
  # Transpose the obtained matrices
  t %>%
  # Consider the matrix as a data frame
  as.data.frame %>%
  # Compute the standard error (standard deviation of the sampling distribution)
  summarize_all(sd)
```

## Logistic Regression
#### If the subject is over 70 kg, the amount of time since drug administration is 1.9e-16 minutes higher than subjects under 70kg. The confusion matrix produced for weight and time was printed. 
```{r}
# Create a binary variable coded as 0 and 1
Theoph_l <- Theoph %>%
  mutate(over_70kg = ifelse(Wt >= 70, 1, 0)) %>%
  mutate(time = ifelse(Time >=5.00, 1, 0))

# Fit a new regression model
fit3 <- glm(over_70kg ~ time, data = Theoph_l, family = binomial(link="logit"))
summary(fit3)

# Interpret the coefficients by considering the odds (inverse of log(odds))
exp(coef(fit3))

# Confusion matrix
table(weight = Theoph_l$over_70kg, time = Theoph_l$time)

# Accuracy (correctly classified cases)
(30 + 35)/132 

# Sensitivity (True Positive Rate, TPR)
35/77

# Specificity (True Negative Rate, TNR)
30/55

# Precision (Positive Predictive Value, PPV)
35/60

# Add predicted probabilities to the dataset
Theoph_l$prob <- predict(fit3, type = "response")

# Predicted outcome is based on the probability of malignant
# if the probability is greater than 0.5, the clump is found to be malignant
Theoph_l$predicted <- ifelse(Theoph_l$prob> .5, "heavier", "lighter") 
Theoph_l
# Plot the model
ggplot(Theoph_l, aes(conc,Wt)) +
  geom_jitter(aes(color = predicted), width = .3, height = 0) +
  stat_smooth(method="glm", method.args = list(family="binomial"), se = FALSE) +
  geom_hline(yintercept = 0.5, lty = 2) +
  ylab("Pr(over_70kg)")

# Save the predicted log-odds in the dataset
Theoph_l$logit <- predict(fit3)


head(Theoph_l)

# Call the library plotROC
library(plotROC) 

# Plot ROC depending on values of y and its probabilities displaying some cutoff values
ROCplot1 <- ggplot(Theoph_l) + 
  geom_roc(aes(d = over_70kg, m = time), cutoffs.at = list(0.1, 0.5, 0.9))
ROCplot1

# Order dataset from least to greatest FPR
#ROC <- ROC %>% 
#  arrange(FPR)

# Calculate horizontal distances
#widths <- diff(ROC$FPR) 

# Calculate vertical distances
#heights <- vector() 
#for(i in 1:100) heights[i] <- ROC$TPR[i] + ROC$TPR[i+1]

# Add the area of each trapezoid
#AUC <- sum(heights * widths / 2)
#AUC
```